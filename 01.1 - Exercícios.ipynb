{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operadores lógicos representados por perceptron\n",
    "\n",
    "<img src=\"images_temp/perceptron_logical_operators.png\"\n",
    "     style=\"float: left; margin-right: 10px; width: 600px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_gate(x1, x2):\n",
    "    w1 = 1.0 #TODO preencher o peso\n",
    "    w2 = 1.0 #TODO preencher o peso\n",
    "    bias = -2 #TODO preencher o bias\n",
    "\n",
    "    eq_linear = w1 * x1 + w2 * x2 + bias #TODO implemente a equação linear\n",
    "    output = int(eq_linear >= 0)\n",
    "    return (eq_linear, output)\n",
    "\n",
    "def or_gate(x1, x2):\n",
    "    w1 = 1.0 #TODO preencher o peso\n",
    "    w2 = 1.0 #TODO preencher o peso\n",
    "    bias = -1 #TODO preencher o bias\n",
    "    \n",
    "    eq_linear = w1 * x1 + w2 * x2 + bias #TODO implemente a equação linear\n",
    "    output = int(eq_linear >= 0)\n",
    "    return (eq_linear, output)\n",
    "\n",
    "def not_gate(x1):\n",
    "    w1 = -1.0 #TODO preencher o peso\n",
    "    bias = 0 #TODO preencher o bias\n",
    "    \n",
    "    eq_linear = w1 * x1 + bias #TODO implemente a equação linear\n",
    "    output = int(eq_linear >= 0)\n",
    "    return (eq_linear, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Descubra os weights e bias para o operador *AND*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [(0,0), (0, 1), (1, 0), (1, 1)]\n",
    "esperado = [False, False, False, True]\n",
    "outputs = []\n",
    "\n",
    "for i, (x1, x2) in enumerate(inputs):\n",
    "    \n",
    "    eq_linear, output = and_gate(x1, x2)\n",
    "    \n",
    "    outputs.append((x1, x2, eq_linear, 'correto' if output == esperado[i] else 'errado'))\n",
    "\n",
    "erros = [out for out in outputs if out[3] == 'errado']\n",
    "\n",
    "output_frame = pd.DataFrame(outputs, columns=['x1', '  x2', '  Eq. Linear', '  Teste'])\n",
    "\n",
    "if not len(erros):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Descubra os weights e bias para o *OR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [(0,0), (0, 1), (1, 0), (1, 1)]\n",
    "esperado = [False, True, True, True]\n",
    "outputs = []\n",
    "\n",
    "for i, (x1, x2) in enumerate(inputs):\n",
    "    \n",
    "    eq_linear, output = or_gate(x1, x2)\n",
    "    \n",
    "    outputs.append((x1, x2, eq_linear, 'correto' if output == esperado[i] else 'errado'))\n",
    "\n",
    "erros = [out for out in outputs if out[3] == 'errado']\n",
    "\n",
    "output_frame = pd.DataFrame(outputs, columns=['x1', '  x2', '  Eq. Linear', '  Teste'])\n",
    "\n",
    "if not len(erros):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Descubra o weigh e bias para o *NOT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [0, 1]\n",
    "esperado = [True, False]\n",
    "outputs = []\n",
    "\n",
    "for i, x1 in enumerate(inputs):\n",
    "    \n",
    "    eq_linear, output = not_gate(x1)\n",
    "    outputs.append((x1, eq_linear, 'correto' if output == esperado[i] else 'errado'))\n",
    "\n",
    "erros = [out for out in outputs if out[2] == 'errado']\n",
    "\n",
    "output_frame = pd.DataFrame(outputs, columns=['x1', '  Eq. Linear', '  Teste'])\n",
    "\n",
    "if not len(erros):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Combine os Perceptrons AND, OR e NOT para formar o operador XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "inputs = [(0,0), (0, 1), (1, 0), (1, 1)]\n",
    "esperado = [False, True, True, False]\n",
    "outputs = []\n",
    "\n",
    "for i, (x1, x2) in enumerate(inputs):\n",
    "    \n",
    "    #TODO combine os perceptrons\n",
    "    _, and_output = and_gate(x1, x2)\n",
    "    _, not_output = not_gate(and_output)\n",
    "    \n",
    "    #outro braço\n",
    "    _, or_output = or_gate(x1, x2)\n",
    "    \n",
    "    #output\n",
    "    eq_linear, output = and_gate(not_output, or_output)\n",
    "    \n",
    "    outputs.append((x1, x2, eq_linear, 'correto' if output == esperado[i] else 'errado'))\n",
    "\n",
    "erros = [out for out in outputs if out[3] == 'errado']\n",
    "\n",
    "output_frame = pd.DataFrame(outputs, columns=['x1', '  x2', '  Eq. Linear', '  Teste'])\n",
    "\n",
    "if not len(erros):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')\n",
    "print(output_frame.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Implemente o algoritmo do perceptron\n",
    "\n",
    "**Algoritmo**\n",
    "<br><br>\n",
    "**Obs:** O sinal para atutalizar o $w_i$ foi invertido do que está na lição!\n",
    "\n",
    "1. Comece com uma reta aleatória\n",
    "2. Para cada ponto classificado errado\n",
    "  1. if previsão == 0<br>\n",
    "    modifique $w_i + \\alpha * x_i$<br>\n",
    "    modifique $b + \\alpha$\n",
    "  2. if previsão == 1<br>\n",
    "    modifique $w_i - \\alpha * x_i$<br>\n",
    "    modifique $b - \\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron trick\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6)) \n",
    "\n",
    "dataset = [(1, 2, 'b', 1), (3, 1.5, 'b', 1), (2, 1, 'b', 1),\n",
    "           (3.5, 2.25, 'g', 0), (2, 3, 'g', 0), (3, 3, 'g', 0)]\n",
    "for x, y, c, _ in dataset:\n",
    "    plt.scatter(x, y, c=c)\n",
    "    \n",
    "#legenda\n",
    "greenPatch = mpatches.Patch(color='green', label='Iris Veriscolor')\n",
    "bluePatch = mpatches.Patch(color='blue', label='Iris Setosa')\n",
    "plt.legend(handles=[greenPatch, bluePatch])\n",
    "\n",
    "plt.title(\"Iris dataset\", fontsize=20)\n",
    "plt.xlabel(\"Largura da Sépala\", fontsize=15)\n",
    "plt.ylabel(\"Comprimento da Sépala\", fontsize=15)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "#desenha a linha\n",
    "x_max = 5\n",
    "x = np.linspace(-1,x_max)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = .5*x +1\n",
    "\n",
    "plt.plot(x, y, linestyle=':')\n",
    "\n",
    "#equação geral da reta x−2y+2=0 \n",
    "w1 = 1\n",
    "w2 = -2\n",
    "b = 2\n",
    "lr = 0.05\n",
    "epochs = 50\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = .5*x +1\n",
    "\n",
    "plt.plot(x, y, linestyle=':')\n",
    "\n",
    "boundaries = []\n",
    "\n",
    "for step in range(epochs):\n",
    "    for x1, x2, c, label in dataset:\n",
    "\n",
    "        # TODO calcule a equação linear\n",
    "        output = None\n",
    "        # TODO com o resultado da equação linear faça a previsão 0 ou 1\n",
    "        pred = None\n",
    "\n",
    "        # TODO se a previsão estiver correta não faça nada, \n",
    "        # apenas de um continue para ir para o proximo item\n",
    "        if None:\n",
    "            continue\n",
    "\n",
    "        # TODO verifique e atualize os pesos e bias de acordo com a posição do ponto\n",
    "        if None:\n",
    "            \n",
    "        else:\n",
    "            \n",
    "\n",
    "        boundaries.append((w1/(w2 * -1), b/(w2 * -1)))\n",
    "\n",
    "# transforma em equação reduzida da reta\n",
    "for i in range(0, len(boundaries[:-1]), 8):\n",
    "    m, b = boundaries[i]\n",
    "    for i in range(len(x)):\n",
    "        y = m*x + b\n",
    "        \n",
    "    plt.plot(x, y, linestyle='--')\n",
    "\n",
    "\n",
    "m, b = boundaries[-1:][0] #ultima boundary\n",
    "\n",
    "for i in range(len(x)):\n",
    "    y = m*x + b\n",
    "    \n",
    "plt.plot(x, y, linestyle='-')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Implemente a função softmax\n",
    "\n",
    "**Scores**: $S_1, ..., S_n$\n",
    "\n",
    "$P(class_i) = \\frac{e^Si}{e^S1 + ... + e^Sn}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(S):\n",
    "    # TODO implemente a função softmax\n",
    "    return [0]\n",
    "\n",
    "S = [2, 1, 0]\n",
    "outputs = softmax(S)\n",
    "print ('Sua saída:', outputs)\n",
    "\n",
    "esperado = [0.66524096, 0.24472847, 0.09003057]\n",
    "corretos = []\n",
    "for i, out in enumerate(outputs):\n",
    "    if round(out, 2) == round(esperado[i], 2):\n",
    "        corretos.append(out)\n",
    "\n",
    "\n",
    "if (len(corretos) == 3):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Implemente Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(Preds, Probs):\n",
    "    return -np.sum((Preds * np.log(Probs) + (1 - Preds) * (np.log(1 - Probs))))\n",
    "\n",
    "Preds = np.array([1, 1, 0])\n",
    "Probs = np.array([0.8, 0.7, 0.1])\n",
    "\n",
    "ce = cross_entropy(Preds, Probs)\n",
    "print ('Sua saída:', ce)\n",
    "\n",
    "esperado = 0.69\n",
    "if round(ce, 2) == round(esperado, 2):\n",
    "    print('Parabéns você acertou!')\n",
    "else:\n",
    "    print('Você possui erros, continue tentando')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
